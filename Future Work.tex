~\label{sec:future_work}
This work is by no means complete. There are plenty of ideas I wish to pursue in the future.

Note that this theory is complete for time-variant systems. The $P$ matrix would have to be redefined but the logic is consistent when $ABCD$ are some function of $k$. This is remarkable because non-linear systems can be modelled with high-accuracy as a sum of many linear time-variant systems. Exploring a non-linear application of the found techniques could then be interesting.

The first item to attack more rigorously and quantify are the trade-offs between $Q$, $R$, $\Phi_u$, $\Phi_y$, and $v(k)$ values. For many examples, it was necessary to drastically increase $R$ to show that the RL framework continued to function, but obviously increased the learning time necessary for a given problem. Exploring ways to reduce $R$ without increasing the necessary exploration terms would drastically improve practicality of learning a controller. Especially in an ILC manufacturing scenario, if one could learn without purposely messing up parts, this would be extremely attractive. Several times, we had to scale up $R$, $v(k)$, and $\Phi_y$ to achieve desirable results in-line with our theory and hopes. Further understanding of why this had to be done, beyond my (questionable) mathematical intuition could open up avenues for incredibly robust and rapid learning controllers in a limited basis space.

Another idea to pursue is to expand on the final example shown in Section~\ref{sec:rl_on_conjugate_basis_ilc}. 
Or rather - reduce it. Instead of constructing a lower-triangular matrix, imagine a scenario where one builds a diagonal controller. Now, each controller could be updated in $4$ trials when a new basis function comes along. If this formulation worked (with a sufficiently small $R$), then it would be possible to find a controller for a complete system in $p(4 + 1)$ trials - $4$ trials for the RL approach and $1$ to generate the associated conjugate basis function. This is essentially what we shown when we learned with $\Phi_y = \lambda \underline{y}^\ast$, except our $\Phi_y$ changes instead of remaining fixed. There may be some benefits to this approach if the system has odd dynamics, or perhaps there are some techniques that benefit from diagonal controllers. I have tried initial passes at this, finding them all to be just barely unstable via pole inspection -- I hope that with a better understanding of $R$ and $\Phi_y$ magnitudes, it would be possible to isolate whether this is an issue of the theory or numerical conditioning.

It would additionally be interesting to figure out what the learned $\underline{u}$ is when the $\Phi_u$ does not capture the $\underline{u}^\ast$. It has been shown to not be the projection of $\underline{u}^\ast$. This is likely due to the fact that the $\underline{u}$ is transformed by the $P$ matrix, and then looped through $\Phi_y^+$ conversions before going back through a controller $\mathcal{L}$ to get $\beta$s (or $\delta \beta$s) all before going back to being a $\underline{u}$. I would suspect that the projection of $\underline{u}^\ast$ is then onto some space that is a transform of $\Phi_u$, with matrices $P$ and $\Phi_y$ involved.

Finally, we have investigated initial steps to reduce dimensions then grow, but no techniques to then work backwards. As shown in Eq.~\ref{eq:conjugate_beta_star}, it is possible to learn the weighting of some inputs even when they were not in the original $\underline{u}^\ast$. It would be desirable to see if there were a way to work backwards to remove certain basis functions, or combine them in with other functions. Take the basis space $\Phi$
\begin{equation}
    \Phi = 
    \begin{bmatrix}
        \phi_1 & \phi_2 & \cdots & \phi_{b-1} & \phi_{b}
    \end{bmatrix}
\end{equation}
that previously satisfied our conjunctionality condition such that
\begin{equation}
    \Phi^T (R + P^T Q P) \Phi = I_{b \times b}
\end{equation}
If we were to combine $\phi_{b-1}$ and $\phi_{b}$ into one term, we could reduce the dimension of our basis space to created $\Phi^\prime$. Now
\begin{equation}
    {\Phi^\prime}^T (R + P^T Q P) \Phi^\prime 
    = 
    \begin{bmatrix}
        I_{(b-2) \times (b-2)} & 0 \\
        0 & 2
    \end{bmatrix}
\end{equation}
The feasibility of this approach is something worth pursing I believe, as it would enable initial input learning through LQL, then an evolving basis space of a fixed dimension that could be set manually. Thus any controllers learned would be able to be done if a fixed amount of trials, set by the user.
