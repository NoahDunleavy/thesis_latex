\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Purpose of Background}{2}{section.1.1}\protected@file@percent }
\AC@undonewlabel{acro:ZOH}
\newlabel{acro:ZOH}{{1.1}{2}{Purpose of Background}{section*.12}{}}
\acronymused{ZOH}
\AC@undonewlabel{acro:LQR}
\newlabel{acro:LQR}{{1.1}{2}{Purpose of Background}{section*.13}{}}
\acronymused{LQR}
\acronymused{ILC}
\acronymused{RL}
\acronymused{LQR}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Introduction to Continuous State Space}{2}{section.1.2}\protected@file@percent }
\newlabel{eq:continuous_state_space_model}{{1.1}{3}{Introduction to Continuous State Space}{equation.1.1}{}}
\newlabel{eq:continuous_state_space_output}{{1.2}{3}{Introduction to Continuous State Space}{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Example --- State Space Formulation}{3}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Dual Spring-Mass-Damper System}}{4}{figure.caption.14}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:spring_mass_system}{{1.1}{4}{Dual Spring-Mass-Damper System}{figure.caption.14}{}}
\newlabel{eq:x1_eom}{{1.3}{4}{Example --- State Space Formulation}{equation.1.3}{}}
\newlabel{eq:x2_eom}{{1.4}{4}{Example --- State Space Formulation}{equation.1.4}{}}
\newlabel{eq:state_vector}{{1.5}{4}{Example --- State Space Formulation}{equation.1.5}{}}
\newlabel{eq:input_vector}{{1.6}{5}{Example --- State Space Formulation}{equation.1.6}{}}
\newlabel{eq:state_vector_derivative}{{1.7}{5}{Example --- State Space Formulation}{equation.1.7}{}}
\newlabel{eq:spring_mass_state_space_continuous}{{1.8}{5}{Example --- State Space Formulation}{equation.1.8}{}}
\newlabel{eq:mass_matrix}{{1.9}{5}{Example --- State Space Formulation}{equation.1.9}{}}
\newlabel{eq:stiffness_matrix}{{1.10}{6}{Example --- State Space Formulation}{equation.1.10}{}}
\newlabel{eq:dampning_matrix}{{1.11}{6}{Example --- State Space Formulation}{equation.1.11}{}}
\newlabel{eq:compact_eom}{{1.12}{6}{Example --- State Space Formulation}{equation.1.12}{}}
\newlabel{eq:spring_mass_state_space_continuous_compact}{{1.13}{6}{Example --- State Space Formulation}{equation.1.13}{}}
\newlabel{eq:mass_matrix_real}{{1.17}{6}{Example --- State Space Formulation}{equation.1.17}{}}
\newlabel{eq:stiffness_matrix_real}{{1.18}{7}{Example --- State Space Formulation}{equation.1.18}{}}
\newlabel{eq:dampning_matrix_real}{{1.19}{7}{Example --- State Space Formulation}{equation.1.19}{}}
\newlabel{eq:spring_mass_state_space_continuous_real}{{1.20}{7}{Example --- State Space Formulation}{equation.1.20}{}}
\newlabel{eq:Ac_Bc_real}{{1.21}{7}{Example --- State Space Formulation}{equation.1.21}{}}
\newlabel{eq:initial_conditions_real}{{1.22}{7}{Example --- State Space Formulation}{equation.1.22}{}}
\newlabel{eq:continuous_output}{{1.23}{8}{Example --- State Space Formulation}{equation.1.23}{}}
\newlabel{eq:C_D_real}{{1.24}{8}{Example --- State Space Formulation}{equation.1.24}{}}
\newlabel{fig:continuous_open_mass_1}{{1.2a}{8}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:continuous_open_mass_1}{{a}{8}{\relax }{figure.caption.15}{}}
\newlabel{fig:continuous_open_mass_2}{{1.2b}{8}{\relax }{figure.caption.15}{}}
\newlabel{sub@fig:continuous_open_mass_2}{{b}{8}{\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Position data from a open-loop continuously-modelled Dual-Spring-Mass system}}{8}{figure.caption.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Discretization of a Continuous Model}{8}{section.1.3}\protected@file@percent }
\acronymused{ZOH}
\newlabel{eq:Ac_to_A}{{1.25}{9}{Discretization of a Continuous Model}{equation.1.25}{}}
\newlabel{eq:Bc_to_B}{{1.26}{9}{Discretization of a Continuous Model}{equation.1.26}{}}
\newlabel{eq:discrete_state_space_model}{{1.27}{9}{Discretization of a Continuous Model}{equation.1.27}{}}
\newlabel{eq:discrete_state_space_output}{{1.28}{9}{Discretization of a Continuous Model}{equation.1.28}{}}
\newlabel{eq:samples_to_time}{{1.29}{9}{Discretization of a Continuous Model}{equation.1.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Example --- Discretization}{10}{subsection.1.3.1}\protected@file@percent }
\newlabel{eq:discrete_A_B}{{1.30}{10}{Example --- Discretization}{equation.1.30}{}}
\newlabel{fig:discrete_open_mass_1}{{1.3a}{11}{\relax }{figure.caption.16}{}}
\newlabel{sub@fig:discrete_open_mass_1}{{a}{11}{\relax }{figure.caption.16}{}}
\newlabel{fig:discrete_open_mass_2}{{1.3b}{11}{\relax }{figure.caption.16}{}}
\newlabel{sub@fig:discrete_open_mass_2}{{b}{11}{\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Position data from an open-loop discretely-modelled Dual-Spring-Mass system, overlaid with the continuous model to show exactness of the relationship}}{11}{figure.caption.16}\protected@file@percent }
\newlabel{fig:zoomed_discrete_open_mass_1}{{1.4a}{11}{\relax }{figure.caption.17}{}}
\newlabel{sub@fig:zoomed_discrete_open_mass_1}{{a}{11}{\relax }{figure.caption.17}{}}
\newlabel{fig:zoomed_discrete_open_mass_2}{{1.4b}{11}{\relax }{figure.caption.17}{}}
\newlabel{sub@fig:zoomed_discrete_open_mass_2}{{b}{11}{\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Zoomed-in view of the discrete-continuous model to show that at the discretely modelled $\Delta t$ time-step samples, the relationship is exact}}{11}{figure.caption.17}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Defining Control}{12}{section.1.4}\protected@file@percent }
\newlabel{eq:control_law}{{1.31}{12}{Defining Control}{equation.1.31}{}}
\newlabel{eq:A_BF_state_space}{{1.33}{12}{Defining Control}{equation.1.33}{}}
\newlabel{eq:scalar_control}{{1.34}{12}{Defining Control}{equation.1.34}{}}
\newlabel{eq:controllability_matrix}{{1.35}{13}{Defining Control}{equation.1.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Example --- Basic Control with Pole Placement}{13}{subsection.1.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Pole locations for a Dual-Spring-Mass system when manually placed them at locations $0.5 +- 0.5i$ and $-0.7 +- 0.1i$}}{14}{figure.caption.18}\protected@file@percent }
\newlabel{fig:simple_poles}{{1.5}{14}{Pole locations for a Dual-Spring-Mass system when manually placed them at locations $0.5 +- 0.5i$ and $-0.7 +- 0.1i$}{figure.caption.18}{}}
\newlabel{eq:simple_pole_controller}{{1.36}{15}{Example --- Basic Control with Pole Placement}{equation.1.36}{}}
\newlabel{eq:example_control_use_u0}{{1.37}{15}{Example --- Basic Control with Pole Placement}{equation.1.37}{}}
\newlabel{fig:simple_pole_mass_1}{{1.6a}{16}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:simple_pole_mass_1}{{a}{16}{\relax }{figure.caption.19}{}}
\newlabel{fig:simple_pole_mass_2}{{1.6b}{16}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:simple_pole_mass_2}{{b}{16}{\relax }{figure.caption.19}{}}
\newlabel{fig:simple_pole_input_1}{{1.6c}{16}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:simple_pole_input_1}{{c}{16}{\relax }{figure.caption.19}{}}
\newlabel{fig:simple_pole_input_2}{{1.6d}{16}{\relax }{figure.caption.19}{}}
\newlabel{sub@fig:simple_pole_input_2}{{d}{16}{\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Position of Mass 1 and Mass 2 for our Dual-Spring-Mass system under closed-loop, state-feedback controller $F$. $F$ is designed such that the poles of ($A+BF$) are at $0.5 +- 0.5i$ and $-0.7 +- 0.1i$. Inputs 1 and 2 are generated as $u(k) = Fx(k)$}}{16}{figure.caption.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Pole locations for a Dual-Spring-Mass system when manually placed them at the origin to produce a deadbeat controller}}{17}{figure.caption.20}\protected@file@percent }
\newlabel{fig:deadbeat_poles}{{1.7}{17}{Pole locations for a Dual-Spring-Mass system when manually placed them at the origin to produce a deadbeat controller}{figure.caption.20}{}}
\newlabel{eq:deadbeat_controller}{{1.38}{18}{Example --- Basic Control with Pole Placement}{equation.1.38}{}}
\newlabel{fig:deadbeat_mass_1}{{1.8a}{18}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:deadbeat_mass_1}{{a}{18}{\relax }{figure.caption.21}{}}
\newlabel{fig:deadbeat_mass_2}{{1.8b}{18}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:deadbeat_mass_2}{{b}{18}{\relax }{figure.caption.21}{}}
\newlabel{fig:deadbeat_input_1}{{1.8c}{18}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:deadbeat_input_1}{{c}{18}{\relax }{figure.caption.21}{}}
\newlabel{fig:deadbeat_input_2}{{1.8d}{18}{\relax }{figure.caption.21}{}}
\newlabel{sub@fig:deadbeat_input_2}{{d}{18}{\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Position of Mass 1 and Mass 2 for our Dual-Spring-Mass system under a deadbeat closed-loop, state-feedback controller $F$. $F$ is designed such that the poles of ($A+BF$) are at $0$. Inputs 1 and 2 are generated as $u(k) = Fx(k)$. Under deadbeat control, it can be seen that control is achieved under $n$ steps}}{18}{figure.caption.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Linear Quadratic Regulator Controller}{19}{section.1.5}\protected@file@percent }
\acronymused{LQR}
\newlabel{eq:utility_function}{{1.39}{19}{Linear Quadratic Regulator Controller}{equation.1.39}{}}
\newlabel{eq:cost_function}{{1.40}{19}{Linear Quadratic Regulator Controller}{equation.1.40}{}}
\newlabel{eq:discounted_cost_function}{{1.41}{20}{Linear Quadratic Regulator Controller}{equation.1.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Illustration of Principle of Optimality, with nodes $A,\ B1,\ B2,\ B,\ $and $C$ with paths between labelled with their associated costs. Even though to go from $A \to B1$ is only a cost of $2$, $B1 \to C$ costs $12$ making the total path cost of $14$. Also see that the path of $A \to B2 \to C$ may have a final step of cost $1$, but the first step has a cost pf $15$. The central path through $B$ then could result in costs of $15,\ 14,\ 11,\ $or $10$. Clearly going through $B$ is the optimal way to proceed. It can then further be seen that the optimal way to go from $B \to C$ is a subset of the optimal path of $A \to C$.}}{21}{figure.caption.22}\protected@file@percent }
\newlabel{fig:principle_optimality}{{1.9}{21}{Illustration of Principle of Optimality, with nodes $A,\ B1,\ B2,\ B,\ $and $C$ with paths between labelled with their associated costs. Even though to go from $A \to B1$ is only a cost of $2$, $B1 \to C$ costs $12$ making the total path cost of $14$. Also see that the path of $A \to B2 \to C$ may have a final step of cost $1$, but the first step has a cost pf $15$. The central path through $B$ then could result in costs of $15,\ 14,\ 11,\ $or $10$. Clearly going through $B$ is the optimal way to proceed. It can then further be seen that the optimal way to go from $B \to C$ is a subset of the optimal path of $A \to C$}{figure.caption.22}{}}
\newlabel{eq:discounted_LQR_solution}{{1.42}{21}{Linear Quadratic Regulator Controller}{equation.1.42}{}}
\newlabel{eq:LQR_solution}{{1.43}{21}{Linear Quadratic Regulator Controller}{equation.1.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Example --- LQR}{21}{subsection.1.5.1}\protected@file@percent }
\newlabel{eq:LQR_params_SMD}{{1.44}{21}{Example --- LQR}{equation.1.44}{}}
\newlabel{eq:F_lqr}{{1.45}{22}{Example --- LQR}{equation.1.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Pole Locations of a Q/R = 100 LQR Controller on our Dual-Spring-Mass System}}{23}{figure.caption.23}\protected@file@percent }
\newlabel{fig:big_Q_poles}{{1.10}{23}{Pole Locations of a Q/R = 100 LQR Controller on our Dual-Spring-Mass System}{figure.caption.23}{}}
\newlabel{fig:big_Q_mass_1}{{1.11a}{24}{\relax }{figure.caption.24}{}}
\newlabel{sub@fig:big_Q_mass_1}{{a}{24}{\relax }{figure.caption.24}{}}
\newlabel{fig:big_Q_mass_2}{{1.11b}{24}{\relax }{figure.caption.24}{}}
\newlabel{sub@fig:big_Q_mass_2}{{b}{24}{\relax }{figure.caption.24}{}}
\newlabel{fig:big_Q_input_1}{{1.11c}{24}{\relax }{figure.caption.24}{}}
\newlabel{sub@fig:big_Q_input_1}{{c}{24}{\relax }{figure.caption.24}{}}
\newlabel{fig:big_Q_input_2}{{1.11d}{24}{\relax }{figure.caption.24}{}}
\newlabel{sub@fig:big_Q_input_2}{{d}{24}{\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Positions of Mass 1 and 2 under a state-feedback controller defined under LQR parameters of Q/R=100. Control is achieved within 200 samples, and under maximum input amplitudes of 55N}}{24}{figure.caption.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Pole Locations of a Q/R = 10 LQR Controller on our Dual-Spring-Mass System}}{25}{figure.caption.25}\protected@file@percent }
\newlabel{fig:big_R_poles}{{1.12}{25}{Pole Locations of a Q/R = 10 LQR Controller on our Dual-Spring-Mass System}{figure.caption.25}{}}
\newlabel{fig:big_R_mass_1}{{1.13a}{26}{\relax }{figure.caption.26}{}}
\newlabel{sub@fig:big_R_mass_1}{{a}{26}{\relax }{figure.caption.26}{}}
\newlabel{fig:big_R_mass_2}{{1.13b}{26}{\relax }{figure.caption.26}{}}
\newlabel{sub@fig:big_R_mass_2}{{b}{26}{\relax }{figure.caption.26}{}}
\newlabel{fig:big_R_input_1}{{1.13c}{26}{\relax }{figure.caption.26}{}}
\newlabel{sub@fig:big_R_input_1}{{c}{26}{\relax }{figure.caption.26}{}}
\newlabel{fig:big_R_input_2}{{1.13d}{26}{\relax }{figure.caption.26}{}}
\newlabel{sub@fig:big_R_input_2}{{d}{26}{\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Positions of Mass 1 and 2 under a state-feedback controller defined under LQR parameters of Q/R=10. Control is achieved within 800 samples, and under maximum input amplitudes of 9N}}{26}{figure.caption.26}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Iterative Learning Control}{27}{section.1.6}\protected@file@percent }
\newlabel{sec:ILC}{{1.6}{27}{Iterative Learning Control}{section.1.6}{}}
\acronymused{ILC}
\newlabel{eq:y_Pu_d}{{1.47}{27}{Iterative Learning Control}{equation.1.47}{}}
\newlabel{eq:y_u_stacks}{{1.48}{28}{Iterative Learning Control}{equation.1.48}{}}
\newlabel{ILC_P}{{1.49}{28}{Iterative Learning Control}{equation.1.49}{}}
\newlabel{eq:y*_Pu*_d}{{1.50}{28}{Iterative Learning Control}{equation.1.50}{}}
\newlabel{eq:delta_operator}{{1.51}{28}{Iterative Learning Control}{equation.1.51}{}}
\newlabel{eq:del_P_with_d}{{1.52}{28}{Iterative Learning Control}{equation.1.52}{}}
\newlabel{eq:del_y_P_del_u}{{1.53}{28}{Iterative Learning Control}{equation.1.53}{}}
\newlabel{eq:e_j_def}{{1.54}{29}{Iterative Learning Control}{equation.1.54}{}}
\newlabel{eq:del_e_law_w_star}{{1.55}{29}{Iterative Learning Control}{equation.1.55}{}}
\newlabel{del_e_law}{{1.56}{29}{Iterative Learning Control}{equation.1.56}{}}
\newlabel{e_j_e_j_1_law}{{1.57}{29}{Iterative Learning Control}{equation.1.57}{}}
\newlabel{eq:e_j_1_e_law}{{1.58}{29}{Iterative Learning Control}{equation.1.58}{}}
\newlabel{eq:ILC_law}{{1.59}{29}{Iterative Learning Control}{equation.1.59}{}}
\newlabel{eq:del_u_L_e_j}{{1.60}{30}{Iterative Learning Control}{equation.1.60}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Example --- ILC}{30}{subsection.1.6.1}\protected@file@percent }
\newlabel{eq:y1_y2_star}{{1.61}{30}{Example --- ILC}{equation.1.61}{}}
\newlabel{eq:stacked_y_star}{{1.62}{30}{Example --- ILC}{equation.1.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Error Progression of an ILC problem when using a perfect knowledge controller $\mathcal  {L} = 0.8P^+$ such that the poles of the system under ($I-P\mathcal  {L}$) are guaranteed to be within the unit circle and relatively close to the origin for rapid convergence.}}{31}{figure.caption.27}\protected@file@percent }
\newlabel{fig:ilc_error}{{1.14}{31}{Error Progression of an ILC problem when using a perfect knowledge controller $\mathcal {L} = 0.8P^+$ such that the poles of the system under ($I-P\mathcal {L}$) are guaranteed to be within the unit circle and relatively close to the origin for rapid convergence}{figure.caption.27}{}}
\newlabel{eq:ilc_controller}{{1.63}{31}{Example --- ILC}{equation.1.63}{}}
\newlabel{fig:ilc_mass_1}{{1.15a}{32}{\relax }{figure.caption.28}{}}
\newlabel{sub@fig:ilc_mass_1}{{a}{32}{\relax }{figure.caption.28}{}}
\newlabel{fig:ilc_mass_2}{{1.15b}{32}{\relax }{figure.caption.28}{}}
\newlabel{sub@fig:ilc_mass_2}{{b}{32}{\relax }{figure.caption.28}{}}
\newlabel{fig:ilc_input_1}{{1.15c}{32}{\relax }{figure.caption.28}{}}
\newlabel{sub@fig:ilc_input_1}{{c}{32}{\relax }{figure.caption.28}{}}
\newlabel{fig:ilc_input_2}{{1.15d}{32}{\relax }{figure.caption.28}{}}
\newlabel{sub@fig:ilc_input_2}{{d}{32}{\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces The progression of Input-Output trials under our controller of $\mathcal  {L} = 0.8P^+$. Trial 1 can be seen to be the open-loop response, and by Trial 10 it can be seen that the output is captured with zero error}}{32}{figure.caption.28}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces Progression of shaped outputs (where Mass 1 Position is the x-coordinate and Mass 2 Position is the y-coordinate) under our ILC controller $\mathcal  {L} = 0.8P^+$}}{33}{figure.caption.29}\protected@file@percent }
\newlabel{fig:ilc_shaped_circle}{{1.16}{33}{Progression of shaped outputs (where Mass 1 Position is the x-coordinate and Mass 2 Position is the y-coordinate) under our ILC controller $\mathcal {L} = 0.8P^+$}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces Application of ILC Controller $\mathcal  {L} = 0.8P^+$ on our Dual-Spring-Mass system to learn the output `Dartmouth'. It can be seen that initial conditions and arbitrariness of different goals has no impact on the efficacy of ILC}}{34}{figure.caption.30}\protected@file@percent }
\newlabel{fig:ilc_shaped_dartmouth}{{1.17}{34}{Application of ILC Controller $\mathcal {L} = 0.8P^+$ on our Dual-Spring-Mass system to learn the output `Dartmouth'. It can be seen that initial conditions and arbitrariness of different goals has no impact on the efficacy of ILC}{figure.caption.30}{}}
\newlabel{fig:dartmouth_ilc_mass_1}{{1.18a}{35}{\relax }{figure.caption.31}{}}
\newlabel{sub@fig:dartmouth_ilc_mass_1}{{a}{35}{\relax }{figure.caption.31}{}}
\newlabel{fig:dartmouth_ilc_mass_2}{{1.18b}{35}{\relax }{figure.caption.31}{}}
\newlabel{sub@fig:dartmouth_ilc_mass_2}{{b}{35}{\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.18}{\ignorespaces Progression of Mass 1 and 2 Positions under controller $\mathcal  {L} = 0.8P^+$, learning `Dartmouth'. It can be seen that Mass 1, the x-position, gradually increases throughout the each trial whereas Mass 2, the y-position, simply moves back-and-forth / up-and-down}}{35}{figure.caption.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Reinforcement Learning}{35}{section.1.7}\protected@file@percent }
\newlabel{eq:cost_to_go}{{1.64}{35}{Reinforcement Learning}{equation.1.64}{}}
\newlabel{eq:gamma_inc_cost_to_go}{{1.65}{35}{Reinforcement Learning}{equation.1.65}{}}
\newlabel{eq:expanded_recurrence}{{1.66}{35}{Reinforcement Learning}{equation.1.66}{}}
\newlabel{eq:recurrence}{{1.67}{36}{Reinforcement Learning}{equation.1.67}{}}
\newlabel{eq:supervector_expanded_ctg}{{1.68}{36}{Reinforcement Learning}{equation.1.68}{}}
\newlabel{eq:supervector_state_input}{{1.69}{36}{Reinforcement Learning}{equation.1.69}{}}
\newlabel{eq:QR_supervector}{{1.70}{36}{Reinforcement Learning}{equation.1.70}{}}
\newlabel{eq:lambda_n}{{1.71}{37}{Reinforcement Learning}{equation.1.71}{}}
\newlabel{eq:lambda_r}{{1.72}{37}{Reinforcement Learning}{equation.1.72}{}}
\newlabel{eq:supervector_ctg}{{1.73}{37}{Reinforcement Learning}{equation.1.73}{}}
\newlabel{eq:xs}{{1.74}{37}{Reinforcement Learning}{equation.1.74}{}}
\newlabel{eq:P1_P2}{{1.75}{38}{Reinforcement Learning}{equation.1.75}{}}
\newlabel{eq:xus_cost_to_go}{{1.78}{38}{Reinforcement Learning}{equation.1.78}{}}
\newlabel{eq:u_s_and_u_s_1}{{1.79}{38}{Reinforcement Learning}{equation.1.79}{}}
\newlabel{eq:xus_to_Rxu}{{1.85}{39}{Reinforcement Learning}{equation.1.85}{}}
\newlabel{eq:q_function}{{1.86}{40}{Reinforcement Learning}{equation.1.86}{}}
\newlabel{eq:q_function_min_recurrence}{{1.88}{40}{Reinforcement Learning}{equation.1.88}{}}
\newlabel{eq:optimal_q_recurrence}{{1.89}{40}{Reinforcement Learning}{equation.1.89}{}}
\newlabel{eq:q_recurrence}{{1.90}{41}{Reinforcement Learning}{equation.1.90}{}}
\newlabel{eq:sym_P_rl}{{1.91}{41}{Reinforcement Learning}{equation.1.91}{}}
\newlabel{eq:F_from_P}{{1.92}{41}{Reinforcement Learning}{equation.1.92}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}Policy Iteration}{41}{subsection.1.7.1}\protected@file@percent }
\newlabel{eq:q-gamma_q}{{1.93}{42}{Policy Iteration}{equation.1.93}{}}
\newlabel{eq:H_prestack}{{1.94}{42}{Policy Iteration}{equation.1.94}{}}
\newlabel{eq:H_stacked}{{1.95}{42}{Policy Iteration}{equation.1.95}{}}
\newlabel{eq:manual_Q_ex}{{1.99}{43}{Policy Iteration}{equation.1.99}{}}
\newlabel{eq:Q_function_kronP}{{1.103}{44}{Policy Iteration}{equation.1.103}{}}
\newlabel{eq:XjPjU}{{1.104}{44}{Policy Iteration}{equation.1.104}{}}
\newlabel{eq:Xj}{{1.105}{45}{Policy Iteration}{equation.1.105}{}}
\newlabel{eq:stacked_Xj_jU}{{1.106}{45}{Policy Iteration}{equation.1.106}{}}
\newlabel{eq:PjXjU}{{1.107}{45}{Policy Iteration}{equation.1.107}{}}
\newlabel{eq:F_from_P_iterative}{{1.108}{45}{Policy Iteration}{equation.1.108}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example --- Policy Iteration}{46}{section*.34}\protected@file@percent }
\newlabel{eq:input_with_exploration}{{1.109}{46}{Example --- Policy Iteration}{equation.1.109}{}}
\newlabel{eq:F_policy}{{1.112}{48}{Example --- Policy Iteration}{equation.1.112}{}}
\newlabel{fig:policy_mass_1}{{1.19a}{48}{\relax }{figure.caption.36}{}}
\newlabel{sub@fig:policy_mass_1}{{a}{48}{\relax }{figure.caption.36}{}}
\newlabel{fig:policy_mass_2}{{1.19b}{48}{\relax }{figure.caption.36}{}}
\newlabel{sub@fig:policy_mass_2}{{b}{48}{\relax }{figure.caption.36}{}}
\newlabel{fig:policy_input_1}{{1.19c}{48}{\relax }{figure.caption.36}{}}
\newlabel{sub@fig:policy_input_1}{{c}{48}{\relax }{figure.caption.36}{}}
\newlabel{fig:policy_input_2}{{1.19d}{48}{\relax }{figure.caption.36}{}}
\newlabel{sub@fig:policy_input_2}{{d}{48}{\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.19}{\ignorespaces Input-Output Data of our Dual-Spring-Mass system under 5 Policy Iteration Trials of 36 samples/steps each. Learning parameters of Q/R = 100 and $\gamma = 0.8$. After 5 controllers, the learning stops and exploration $v(k)$ is no longer applied to the input for the final 20 trials.}}{48}{figure.caption.36}\protected@file@percent }
\newlabel{fig:policy_F1_history}{{1.20a}{49}{\relax }{figure.caption.37}{}}
\newlabel{sub@fig:policy_F1_history}{{a}{49}{\relax }{figure.caption.37}{}}
\newlabel{fig:policy_F2_history}{{1.20b}{49}{\relax }{figure.caption.37}{}}
\newlabel{sub@fig:policy_F2_history}{{b}{49}{\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.20}{\ignorespaces Progression of controller weights through Policy Iteration Trials. For two inputs, there are two rows of the controller $F$ to describe how to weight their respective inputs from the associated samples collected states.}}{49}{figure.caption.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.2}Input Decoupling}{49}{subsection.1.7.2}\protected@file@percent }
\newlabel{eq:stacked_inputs}{{1.113}{49}{Input Decoupling}{equation.1.113}{}}
\newlabel{eq:stacked_controllers}{{1.114}{50}{Input Decoupling}{equation.1.114}{}}
\newlabel{eq:P_id}{{1.119}{51}{Input Decoupling}{equation.1.119}{}}
\newlabel{eq:id_q_function}{{1.120}{51}{Input Decoupling}{equation.1.120}{}}
\newlabel{eq:Pi_matrix}{{1.124}{52}{Input Decoupling}{equation.1.124}{}}
\newlabel{eq:Fi_from_Pi}{{1.125}{52}{Input Decoupling}{equation.1.125}{}}
\newlabel{eq:Xij}{{1.126}{52}{Input Decoupling}{equation.1.126}{}}
\newlabel{eq:Fi_from_Pi_iterative}{{1.127}{52}{Input Decoupling}{equation.1.127}{}}
\@writefile{toc}{\contentsline {subsubsection}{Example --- Input Decoupling}{53}{section*.39}\protected@file@percent }
\newlabel{sub:example_input_decoupling}{{1.7.2}{53}{Example --- Input Decoupling}{section*.39}{}}
\newlabel{eq:F_input_decoupled}{{1.130}{54}{Example --- Input Decoupling}{equation.1.130}{}}
\newlabel{fig:id_mass_1}{{1.21a}{54}{\relax }{figure.caption.41}{}}
\newlabel{sub@fig:id_mass_1}{{a}{54}{\relax }{figure.caption.41}{}}
\newlabel{fig:id_mass_2}{{1.21b}{54}{\relax }{figure.caption.41}{}}
\newlabel{sub@fig:id_mass_2}{{b}{54}{\relax }{figure.caption.41}{}}
\newlabel{fig:id_input_1}{{1.21c}{54}{\relax }{figure.caption.41}{}}
\newlabel{sub@fig:id_input_1}{{c}{54}{\relax }{figure.caption.41}{}}
\newlabel{fig:id_input_2}{{1.21d}{54}{\relax }{figure.caption.41}{}}
\newlabel{sub@fig:id_input_2}{{d}{54}{\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.21}{\ignorespaces Input-Output Data of Dual-Spring-Mass system under Input Decoupled Learning. 5 passes are made on each input, of which we have two, and requires 25 trials each. Learning is halted fir the final 20 trials which can be seen by both inputs being smooth at the same time.}}{54}{figure.caption.41}\protected@file@percent }
\newlabel{fig:id_F1_history}{{1.22a}{55}{\relax }{figure.caption.42}{}}
\newlabel{sub@fig:id_F1_history}{{a}{55}{\relax }{figure.caption.42}{}}
\newlabel{fig:id_F2_history}{{1.22b}{55}{\relax }{figure.caption.42}{}}
\newlabel{sub@fig:id_F2_history}{{b}{55}{\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.22}{\ignorespaces Progression of Controller Weights through Input-Decoupled trials. Notice how for the dual-input system, the weights for a given input are only updated every other trial.}}{55}{figure.caption.42}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Summary}{55}{section.1.8}\protected@file@percent }
\@setckpt{Background}{
\setcounter{page}{56}
\setcounter{equation}{130}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{7}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{22}
\setcounter{table}{0}
\setcounter{caption@flags}{6}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{2}
\setcounter{subtable}{0}
\setcounter{section@level}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{7}
\setcounter{bookmark@seq@number}{21}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{lstlisting}{0}
}
